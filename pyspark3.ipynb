{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "DF\n",
        "\n",
        "ways to create\n",
        "\n",
        "3 ways\n",
        "\n",
        "1. createDataFrame\n",
        "2. converting RDD\n",
        "3. data source\n",
        "\n",
        "\n",
        "===============\n",
        "\n",
        "txt/csv file  ==> 1 GB\n",
        "parquet == > 50-60% 400MB - 450MB   ==> columnar based file format\n",
        "avro    == > 40-50% 550MB - 600MB   ==> row based file format\n",
        "ORC     == > 90-95% 100Mb - 150MB   ==> columnar based file format\n",
        "\n",
        "\n",
        "\n",
        "select city, min(salary), avg(salary) from employees group by city\n",
        "\n",
        "\n",
        "\n",
        "20 columns\n",
        "\n",
        "1TB\n",
        "\n",
        "columnar based\n",
        "processing 1 column ==> 50GB\n",
        "\n",
        "Row based\n",
        "processing 1 column ==> 1TB\n",
        "\n",
        "\n",
        "New%  --> startsWith\n",
        "\n",
        "%New  --> endsWith\n",
        "\n",
        "%New%  --> contains\n"
      ],
      "metadata": {
        "id": "wnrnNBiA4r-z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvIHJq813O74",
        "outputId": "ca4ff9ed-3e01-41cb-adbb-61da9c6b27f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------------+\n",
            "| id|           name|\n",
            "+---+---------------+\n",
            "|  1|DD37Cf93aecA6Dc|\n",
            "|  2|1Ef7b82A4CAAD10|\n",
            "|  3|6F94879bDAfE5a6|\n",
            "|  4|5Cef8BFA16c5e3c|\n",
            "|  5|053d585Ab6b3159|\n",
            "|  6|2d08FB17EE273F4|\n",
            "|  7|EA4d384DfDbBf77|\n",
            "|  8|0e04AFde9f225dE|\n",
            "|  9|C2dE4dEEc489ae0|\n",
            "| 10|8C2811a503C7c5a|\n",
            "| 11|216E205d6eBb815|\n",
            "| 12|CEDec94deE6d69B|\n",
            "| 13|e35426EbDEceaFF|\n",
            "| 14|A08A8aF8BE9FaD4|\n",
            "| 15|6fEaA1b7cab7B6C|\n",
            "| 16|8cad0b4CBceaeec|\n",
            "| 17|a5DC21AE3a21eaA|\n",
            "| 18|F8Aa9d6DfcBeeF8|\n",
            "| 19|F160f5Db3EfE973|\n",
            "| 20|0F60FF3DdCd7aB0|\n",
            "+---+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#reading CSV file---> This is for small data\n",
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
        "from pyspark.sql import SparkSession\n",
        "Spark = SparkSession.builder.appName(\"practice\").getOrCreate()\n",
        "schema = StructType([\n",
        "    StructField(\"id\", IntegerType(), True),\n",
        "    StructField(\"name\", StringType(), True)\n",
        "])\n",
        "csv_df = Spark.read.format('csv').option('header','true').schema(schema).load(\"/content/customers-100.csv\")\n",
        "csv_df.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parquet file ------> This type of files are used in the 6 - months data and aslo one year of data\n",
        "#Its a column based storage\n",
        "#Processing is very fast compare to ORC file.\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import *\n",
        "Spark = SparkSession.builder.appName('pratice3').getOrCreate()\n",
        "schema1 = StructType([\n",
        "    StructField('id',IntegerType(),True),\n",
        "    StructField('name',StringType(),True)\n",
        "   ])\n",
        "df2 = Spark.read.parquet(\"/content/data.parquet\")\n",
        "df2.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4STRqobMmwKp",
        "outputId": "b3cac714-136a-4dbf-c012-4e1ae75ce337"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+--------+----------------+\n",
            "|      id|     tdate|category|         product|\n",
            "+--------+----------+--------+----------------+\n",
            "|00000000|06-26-2011|Exercise|Gymnastics Rings|\n",
            "|00000002|06-01-2011|Exercise|Gymnastics Rings|\n",
            "+--------+----------+--------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ORC file reading\n",
        "# It is used for Historical data.\n",
        "# Maximum file compression will happend here only compare to parquet file.\n",
        "# processing file is to late compare to parquet.\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import *\n",
        "spark = SparkSession.builder.appName('pratice4').getOrCreate()\n",
        "df3 = spark.read.orc(\"/content/data.orc\")\n",
        "df3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYJLrjB2w5W3",
        "outputId": "8b3f2ef8-3e18-401d-d92a-2d783620bb9f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+--------------------+------------------+-----------+----------+-----+-----+---+------------+------------+--------------------+--------------------+\n",
            "|first_name|last_name|        company_name|           address|       city|    county|state|  zip|age|      phone1|      phone2|               email|                 web|\n",
            "+----------+---------+--------------------+------------------+-----------+----------+-----+-----+---+------------+------------+--------------------+--------------------+\n",
            "|   Solange|   Shinko|   Mosocco, Ronald A|       426 Wolf St|   Metairie| Jefferson|   LA|70002| 21|504-979-9175|504-265-8174|  solange@shinko.com|http://www.mosocc...|\n",
            "|    Arlene|  Klusman|Beck Horizon Buil...|        3 Secor Rd|New Orleans|   Orleans|   LA|70112| 20|504-710-5840|504-946-1807|arlene_klusman@gm...|http://www.beckho...|\n",
            "|     Larae|   Gudroe|Lehigh Furn Divsn...| 6651 Municipal Rd|      Houma|Terrebonne|   LA|70360| 33|985-890-7262|985-261-5783|larae_gudroe@gmai...|http://www.lehigh...|\n",
            "| Willodean|Konopacki|            Magnuson| 55 Hawthorne Blvd|  Lafayette| Lafayette|   LA|70506| 22|337-253-8384|337-774-7564|willodean_konopac...|http://www.magnus...|\n",
            "|  Terrilyn|Rodeigues|      Stuart J Agins|    3718 S Main St|New Orleans|   Orleans|   LA|70130| 33|504-463-4384|504-635-8518|terrilyn.rodeigue...|http://www.stuart...|\n",
            "|  Kayleigh|     Lace|Dentalaw Divsn Hl...|43 Huey P Long Ave|  Lafayette| Lafayette|   LA|70508| 11|337-740-9323|337-751-2326|kayleigh.lace@yah...|http://www.dental...|\n",
            "|     Jutta|    Amyot|National Medical ...|      49 N Mays St|  Broussard| Lafayette|   LA|70518| 15|337-515-1438|337-991-8070|  jamyot@hotmail.com|http://www.nation...|\n",
            "|  Cordelia| Storment|  Burrows, Jon H Esq|    393 Hammond Dr|  Lafayette| Lafayette|   LA|70506| 16|337-566-6001|337-255-3427|cordelia_storment...|http://www.burrow...|\n",
            "+----------+---------+--------------------+------------------+-----------+----------+-----+-----+---+------------+------------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a dataframe and by using withColumn creating one more column for getting the status.\n",
        "from pyspark import status\n",
        "from pyspark.sql.functions import *\n",
        "data = ((1, 'charan',28),(2,'dheeraj',17),(3,'ram',62))\n",
        "columns = ['id','name','age']\n",
        "df = Spark.createDataFrame(data,columns)\n",
        "results = df.show\n",
        "print(results)\n",
        "results = df.withColumn('status',when(df.age <=17,'minor')\\\n",
        "                        .when((df.age >=18) & (df.age <=60),'major')\\\n",
        "                        .otherwise('senior'))\n",
        "results.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkxVkAuyAJRj",
        "outputId": "2dba7b22-94da-4eb6-fb8f-23810a532b9d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method DataFrame.show of DataFrame[id: bigint, name: string, age: bigint]>\n",
            "+---+-------+---+------+\n",
            "| id|   name|age|status|\n",
            "+---+-------+---+------+\n",
            "|  1| charan| 28| major|\n",
            "|  2|dheeraj| 17| minor|\n",
            "|  3|    ram| 62|senior|\n",
            "+---+-------+---+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import status\n",
        "from pyspark.sql.functions import *\n",
        "data = ((1, 'charan',28),(2,'dheeraj',17),(3,'ram',62))\n",
        "columns = ['id','name','age']\n",
        "df = Spark.createDataFrame(data,columns)\n",
        "results = df.show\n",
        "print(results)\n",
        "results = df.withCo('status'when(df.age <=17,'minor')\n",
        ".when((df.age >=18) & (df.age <=60),'adult')\n",
        ".otherwise('senior'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rE8Bv2y63WHv",
        "outputId": "8613e65f-8830-43de-a5b6-7167d49a6e7a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method DataFrame.show of DataFrame[id: bigint, name: string, age: bigint]>\n",
            "+---+-------+---+------+\n",
            "| id|   name|age|status|\n",
            "+---+-------+---+------+\n",
            "|  1| charan| 28| adult|\n",
            "|  2|dheeraj| 17| minor|\n",
            "|  3|    ram| 62|senior|\n",
            "+---+-------+---+------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}