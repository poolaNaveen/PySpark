{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMmMFE6SYNBZNm9kesB51o5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poolaNaveen/PySpark/blob/main/Pyspark2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8RgiQ_gsnC1",
        "outputId": "d2ef51ec-51c2-472c-900b-b13784d6478e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: long (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('day2').getOrCreate()\n",
        "data = ((1,'naveen'),(2,'manoj'),(3,'kiran'))\n",
        "columns = ['id','name']\n",
        "df = spark.createDataFrame(data, columns)\n",
        "df.printSchema()\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = ((1, 'charan'),\n",
        "        (2, 'naveen'),\n",
        "        (3, 'manoj'),\n",
        "        (4, 'kiran'))\n",
        "columns = ['id','name']\n",
        "df1 = spark.createDataFrame(data,columns)\n",
        "df1.printSchema()\n",
        "rdd = spark.sparkContext.parallelize(data)\n",
        "df2 = rdd.toDF()\n",
        "\n"
      ],
      "metadata": {
        "id": "6CFmvRfuCsgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "data = SparkSession.builder.appName('day4').getOrCreate()\n",
        "data1 = [(1,'charan'),(2,'naveen'),(3,'manoj'),(4,'kiran')]\n",
        "columns = ['id','name']\n",
        "df1 = data.CreateDataFrame(data,columns)\n",
        "df1.show()"
      ],
      "metadata": {
        "id": "osR1kRLQDkZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
        "\n",
        "schema = StructType ( [\n",
        "    StructField (\"id\", IntegerType(), False),\n",
        "    StructField (\"name\", StringType(), True),\n",
        "])\n",
        "\n",
        "df3 = spark.createDataFrame(data, schema=schema)\n",
        "\n",
        "df3.printSchema()"
      ],
      "metadata": {
        "id": "2aCVyRIfHAGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = StructType ( [\n",
        "    StructField (\"id\", IntegerType(), False),\n",
        "    StructField (\"name\", StringType(), False),\n",
        "])\n",
        "\n",
        "csv_df = spark.read.format(\"csv\").option(\"header\", 'true').schema(columns).load(\"source.csv\")\n",
        "csv_df.show()\n",
        "csv_df.printSchema()"
      ],
      "metadata": {
        "id": "q7aYdIZQHHDp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}