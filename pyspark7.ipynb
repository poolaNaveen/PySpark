{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO60C2moS2eQOqyAHA9viKW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poolaNaveen/PySpark/blob/main/pyspark7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Before running a any Delta format file we need to install all configuration.\n",
        "#2.Delta tables are used because they bring ACID transactions, version control, schema enforcement, fast performance, and safe concurrent writing to data lakes—something normal Parquet/CSV files cannot do.\n",
        "#3.!apt-get install default-jdk -y\n",
        "#4.!pip install pyspark delta-spark\n",
        "#5.from pyspark.sql import SparkSession\n",
        "from delta import configure_spark_with_delta_pip\n",
        "\n",
        "builder = SparkSession.builder \\\n",
        "    .appName(\"DeltaLocal\") \\\n",
        "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
        "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
        "\n",
        "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n"
      ],
      "metadata": {
        "id": "U1atWEwHHhgS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXxhYpMtE8gg",
        "outputId": "fef0316d-c104-41b0-9faa-44e3737f3ac5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  at-spi2-core default-jdk-headless default-jre default-jre-headless\n",
            "  fonts-dejavu-core fonts-dejavu-extra gsettings-desktop-schemas\n",
            "  libatk-bridge2.0-0 libatk-wrapper-java libatk-wrapper-java-jni libatk1.0-0\n",
            "  libatk1.0-data libatspi2.0-0 libxcomposite1 libxt-dev libxtst6 libxxf86dga1\n",
            "  openjdk-11-jdk openjdk-11-jdk-headless openjdk-11-jre\n",
            "  openjdk-11-jre-headless session-migration x11-utils\n",
            "Suggested packages:\n",
            "  libxt-doc openjdk-11-demo openjdk-11-source visualvm libnss-mdns\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  | fonts-wqy-zenhei fonts-indic mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  at-spi2-core default-jdk default-jdk-headless default-jre\n",
            "  default-jre-headless fonts-dejavu-core fonts-dejavu-extra\n",
            "  gsettings-desktop-schemas libatk-bridge2.0-0 libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libatk1.0-0 libatk1.0-data libatspi2.0-0\n",
            "  libxcomposite1 libxt-dev libxtst6 libxxf86dga1 openjdk-11-jdk\n",
            "  openjdk-11-jdk-headless openjdk-11-jre openjdk-11-jre-headless\n",
            "  session-migration x11-utils\n",
            "0 upgraded, 24 newly installed, 0 to remove and 41 not upgraded.\n",
            "Need to get 122 MB of archives.\n",
            "After this operation, 275 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatspi2.0-0 amd64 2.44.0-3 [80.9 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 session-migration amd64 0.3.6 [9,774 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 gsettings-desktop-schemas all 42.0-1ubuntu1 [31.1 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 at-spi2-core amd64 2.44.0-3 [54.4 kB]\n",
            "Ign:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jre-headless amd64 11.0.28+6-1ubuntu1~22.04.1\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 default-jre-headless amd64 2:1.11-72build2 [3,042 B]\n",
            "Ign:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jre amd64 11.0.28+6-1ubuntu1~22.04.1\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 default-jre amd64 2:1.11-72build2 [896 B]\n",
            "Ign:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jdk-headless amd64 11.0.28+6-1ubuntu1~22.04.1\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 default-jdk-headless amd64 2:1.11-72build2 [942 B]\n",
            "Ign:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jdk amd64 11.0.28+6-1ubuntu1~22.04.1\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 default-jdk amd64 2:1.11-72build2 [908 B]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-core all 2.37-2build1 [1,041 kB]\n",
            "Err:6 http://security.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jre-headless amd64 11.0.28+6-1ubuntu1~22.04.1\n",
            "  404  Not Found [IP: 185.125.190.81 80]\n",
            "Err:8 http://security.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jre amd64 11.0.28+6-1ubuntu1~22.04.1\n",
            "  404  Not Found [IP: 185.125.190.81 80]\n",
            "Err:10 http://security.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jdk-headless amd64 11.0.28+6-1ubuntu1~22.04.1\n",
            "  404  Not Found [IP: 185.125.190.81 80]\n",
            "Err:12 http://security.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jdk amd64 11.0.28+6-1ubuntu1~22.04.1\n",
            "  404  Not Found [IP: 185.125.190.81 80]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-extra all 2.37-2build1 [2,041 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk1.0-data all 2.36.0-3build1 [2,824 B]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk1.0-0 amd64 2.36.0-3build1 [51.9 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-bridge2.0-0 amd64 2.38.0-3 [66.6 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcomposite1 amd64 1:0.4.5-1build2 [7,192 B]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu3 [12.6 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-utils amd64 7.7+5build2 [206 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java all 0.38.0-5build1 [53.1 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java-jni amd64 0.38.0-5build1 [49.0 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxt-dev amd64 1:1.2.1-1 [396 kB]\n",
            "Fetched 4,122 kB in 2s (2,443 kB/s)\n",
            "E: Failed to fetch http://security.ubuntu.com/ubuntu/pool/main/o/openjdk-lts/openjdk-11-jre-headless_11.0.28%2b6-1ubuntu1%7e22.04.1_amd64.deb  404  Not Found [IP: 185.125.190.81 80]\n",
            "E: Failed to fetch http://security.ubuntu.com/ubuntu/pool/main/o/openjdk-lts/openjdk-11-jre_11.0.28%2b6-1ubuntu1%7e22.04.1_amd64.deb  404  Not Found [IP: 185.125.190.81 80]\n",
            "E: Failed to fetch http://security.ubuntu.com/ubuntu/pool/main/o/openjdk-lts/openjdk-11-jdk-headless_11.0.28%2b6-1ubuntu1%7e22.04.1_amd64.deb  404  Not Found [IP: 185.125.190.81 80]\n",
            "E: Failed to fetch http://security.ubuntu.com/ubuntu/pool/main/o/openjdk-lts/openjdk-11-jdk_11.0.28%2b6-1ubuntu1%7e22.04.1_amd64.deb  404  Not Found [IP: 185.125.190.81 80]\n",
            "E: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\n"
          ]
        }
      ],
      "source": [
        "!apt-get install default-jdk -y\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark delta-spark\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fl7l4uPuFX-B",
        "outputId": "b856de88-9137-46ff-f514-7206a1e4789d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Collecting delta-spark\n",
            "  Downloading delta_spark-4.0.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-4.0.1.tar.gz (434.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.2/434.2 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: importlib-metadata>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from delta-spark) (8.7.0)\n",
            "Collecting py4j==0.10.9.9 (from pyspark)\n",
            "  Downloading py4j-0.10.9.9-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata>=1.0.0->delta-spark) (3.23.0)\n",
            "Downloading delta_spark-4.0.0-py3-none-any.whl (39 kB)\n",
            "Downloading py4j-0.10.9.9-py2.py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.0/203.0 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-4.0.1-py2.py3-none-any.whl size=434813800 sha256=2227c6e55509a4c567bf16b5159179f822080ae8f4d9f74f9e2d64fc9d3c5448\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/9f/68/f89fb34ccd886909be7d0e390eaaf97f21efdf540c0ee8dbcd\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark, delta-spark\n",
            "  Attempting uninstall: py4j\n",
            "    Found existing installation: py4j 0.10.9.7\n",
            "    Uninstalling py4j-0.10.9.7:\n",
            "      Successfully uninstalled py4j-0.10.9.7\n",
            "  Attempting uninstall: pyspark\n",
            "    Found existing installation: pyspark 3.5.1\n",
            "    Uninstalling pyspark-3.5.1:\n",
            "      Successfully uninstalled pyspark-3.5.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dataproc-spark-connect 0.8.3 requires pyspark[connect]~=3.5.1, but you have pyspark 4.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed delta-spark-4.0.0 py4j-0.10.9.9 pyspark-4.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from delta.tables import DeltaTable\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"LocalDelta\") \\\n",
        "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
        "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
        "    .config(\"spark.databricks.delta.schema.autoMerge.enabled\", 'true') \\\n",
        "    .getOrCreate()\n",
        "\n",
        "\n",
        "data = [(1, \"Charan\"), (2, \"Ram\")]\n",
        "df = spark.createDataFrame(data, [\"id\", \"name\"])\n",
        "\n",
        "df.write.format(\"delta\").mode(\"overwrite\").save(\"emp2\")\n",
        "\n",
        "existing_table = DeltaTable.forPath(spark, \"emp2\")\n",
        "new_data = spark.createDataFrame([(1, \"Charan C\"), (4, \"Suresh\")], [\"id\", \"name\"])\n",
        "\n",
        "existing_table.alias(\"e\").merge(\n",
        "    new_data.alias(\"n\"),\n",
        "    \"e.id = n.id\"\n",
        ").whenMatchedUpdateAll() \\\n",
        " .whenNotMatchedInsertAll() \\\n",
        " .execute()\n",
        "\n",
        "df = spark.read.format(\"delta\").load(\"emp2\")\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oazRXUCkR3Kf",
        "outputId": "81d45d85-d091-450d-b2ef-0c7929294e45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------+\n",
            "| id|    name|\n",
            "+---+--------+\n",
            "|  1|Charan C|\n",
            "|  4|  Suresh|\n",
            "|  2|     Ram|\n",
            "+---+--------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}